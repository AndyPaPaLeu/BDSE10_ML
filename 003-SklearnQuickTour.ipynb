{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 學習目標\n",
    "\n",
    "### 1. 雙月亮資料集\n",
    "觀察不同演算法的決策邊界差異性，並利用此資料集來快速認識Scikit-Learn。\n",
    "\n",
    "\n",
    "### 2. 手寫數字資料集\n",
    "\n",
    "介紹完整的機器學習流程，包含\n",
    "   * 資料準備\n",
    "   * 標準化\n",
    "   * 模型建立\n",
    "   * 調整參數優化模型\n",
    "   * 模型檢驗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.雙月亮](#1.-雙月亮)\n",
    "\n",
    "[1.a. 資料準備](#1.a.-資料準備)\n",
    "\n",
    "[1.b. 資料標準化](#1.b.-資料標準化)\n",
    "\n",
    "[1.c. 模型建立](#1.c.-模型建立)\n",
    "* [1.c.I. KNN](#1.c.I.-KNN)\n",
    "* [1.c.II. Linear SVM](#1.c.II.-Linear-SVM)\n",
    "* [1.c.III. SVM with Gaussian Kernel](#1.c.III.-SVM-with-Gaussian-Kernel)\n",
    "* [1.c.IV. Logistic Regression](#1.c.IV.-Logistic-Regression)\n",
    "\n",
    "### [2.手寫數字](#2.-手寫數字)\n",
    "[2.a. 利用Pandas, 可迅速了解每個資料夾裡面有幾張圖片](#2.a.-利用Pandas,-可迅速了解每個資料夾裡面有幾張圖片)\n",
    "\n",
    "[2.b. 將圖片路徑資訊分成70% train, 10% val, 20% test](#2.b.-將圖片路徑資訊分成70%-train,-10%-val,-20%-test)\n",
    "\n",
    "[2.c. 將圖片載入，存成數值矩陣](#2.c.-將圖片載入，存成數值矩陣)\n",
    "\n",
    "[2.d. 將28X28的圖片特徵轉換成一維](#2.d.-將28X28的圖片特徵轉換成一維)\n",
    "\n",
    "[2.e. 以羅吉斯回歸建立分類模型](#2.e.-以羅吉斯回歸建立分類模型)\n",
    "\n",
    "[2.f. 製作分類結果報告，並畫出混淆矩陣](#2.f.-製作分類結果報告，並畫出混淆矩陣)\n",
    "\n",
    "[2.g. 建模: 資料分成train, validation, test三份](#2.g.-建模:-資料分成train,-validation,-test三份)\n",
    "   * [2.g.I. 以train data來建立模型，並將該模型以validation data 來檢驗，藉此優化模型參數](#2.g.I.-以train-data來建立模型，並將該模型以validation-data-來檢驗，藉此優化模型參數)\n",
    "   * [2.g.II. 將模型內的權重視覺化](#2.g.II.-將模型內的權重視覺化)\n",
    "   * [2.g.III. 以test data來確定建立好的模型是否完善](#2.g.III.-以test-data來確定建立好的模型是否完善)\n",
    "\n",
    "[2.h. 另一種更嚴謹的建模方式：k-fold cross validation](#2.h.-另一種更嚴謹的建模方式：k-fold-cross-validation)\n",
    "   * [2.h.I. 以5-fold 交叉驗證來調整模型參數: 使用GridSearchCV](#2.h.I.-以5-fold-交叉驗證來調整模型參數:-使用GridSearchCV)\n",
    "   * [2.h.II. 看哪種參數組合有最高的f1 score](#2.h.II.-看哪種參數組合有最高的f1-score)\n",
    "   * [2.h.III. 最後，拿最好的模型，去看該模型是否亦適用於test data](#2.h.III.-最後，拿最好的模型，去看該模型是否亦適用於test-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題1.](#問題1.)\n",
    "[問題2.](#問題2.)\n",
    "[問題3.](#問題3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 雙月亮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a. 資料準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X,y=make_moons(n_samples=100)\n",
    "colors=['r','b']\n",
    "\n",
    "#畫兩個月亮\n",
    "moonRed=plt.scatter(X[y==0,0],X[y==0,1],marker='v', color=colors[0],lw=0,label=\"red moon\")\n",
    "moonBLue=plt.scatter(X[y==1,0],X[y==1,1],marker='s', color=colors[1],lw=0,label=\"blue moon\")\n",
    "plt.legend([moonRed, moonBLue],[\"red moon\",\"blue moon\"],scatterpoints=1,loc='lower left')\n",
    "plt.title('double moon')\n",
    "plt.show()\n",
    "\n",
    "#畫兩個月亮+雜訊\n",
    "variance=0.25\n",
    "randMatrix=np.hstack((np.random.normal(0,variance,100).reshape(-1,1),\n",
    "                      np.random.normal(0,variance,100).reshape(-1,1)))\n",
    "X=(randMatrix+X)\n",
    "\n",
    "moonRed=plt.scatter(X[y==0,0],X[y==0,1],marker='v', color=colors[0],lw=0,label=\"red moon\")\n",
    "moonBLue=plt.scatter(X[y==1,0],X[y==1,1],marker='s', color=colors[1],lw=0,label=\"blue moon\")\n",
    "plt.title('double moon + noise')\n",
    "plt.legend([moonRed, moonBLue],[\"red moon\",\"blue moon\"],scatterpoints=1,loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. 資料標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "fitter=scaler.fit(X)\n",
    "# fitter.mean_   # 看MEAN\n",
    "# fitter.var_    # 看VARIANCE\n",
    "X=fitter.transform(X)\n",
    "\n",
    "# # 確定資料是否有標準化\n",
    "print( 'mean=',X[:,0].mean(),'\\t std=',X[:,0].std() )\n",
    "print( 'mean=',X[:,1].mean(),'\\t std=',X[:,1].std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 為何要做資料標準化？\n",
    "    \n",
    "Reference: http://sebastianraschka.com/Articles/2014_about_feature_scaling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c. 資料準備模型建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c.I. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "model=classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "註： data需要是shape=```(#examples,features)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([X[:,0],X[:,1],y]).T\n",
    "df.columns=[\"x1\",\"x2\",'label']\n",
    "groups=df.groupby(\"label\")\n",
    "groups.indices\n",
    "color=[\"red\",\"blue\"]\n",
    "for idx,(name,group) in enumerate(groups):\n",
    "    print(idx,name)\n",
    "    plt.scatter(group[\"x1\"],group[\"x2\"],color=color[idx],label=name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plt.figure()\n",
    "plot_decision_regions(X,y,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c.II. Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由Scikit-Learn說明，我們得知，於線性SVM時，LinearSVC相較於SVC來說，有較多參數可以調整，且於計算大量數據時應較為迅速。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier=LinearSVC()\n",
    "model=classifier.fit(X,y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plt.figure()\n",
    "plot_decision_regions(X,y,model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LinearSVC(penalty=\"l1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題1. \n",
    "* multi_class='ovr'是什麼意思？\n",
    "* l1/l2 penalty是什麼？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c.III. SVM with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC基於libsvm, libsvm是台灣大學林智仁所開發。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier=SVC()\n",
    "model=classifier.fit(X,y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plt.figure()\n",
    "plot_decision_regions(X,y,classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kernel='rbf'是什麼意思？\n",
    "* probability=True是什麼意思？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://stats.stackexchange.com/questions/63881/use-gaussian-rbf-kernel-for-mapping-of-2d-data-to-3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c.IV. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=LogisticRegression()\n",
    "\n",
    "model=classifier.fit(X,y)\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plt.figure()\n",
    "plot_decision_regions(X,y,model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y == pred).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred==y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上等同於："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題3. \n",
    "LogisticRegression()的參數中，multi_class的值有哪些可能性，分別有什麼意義？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn API: http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  2. 手寫數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filePathsGen(rootPath):\n",
    "    paths=[]\n",
    "    dirs=[]\n",
    "    for dirPath,dirNames,fileNames in os.walk(rootPath):\n",
    "        for fileName in fileNames:\n",
    "            fullPath=os.path.join(dirPath,fileName)\n",
    "            paths.append((int(dirPath[len(rootPath) ]),fullPath))\n",
    "        dirs.append(dirNames)\n",
    "    return dirs,paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs,paths=filePathsGen('../datasets/mnist/') #載入圖片路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath=pd.DataFrame(paths,columns=['class','path']) #圖片路徑存成Pandas資料表\n",
    "dfPath.head(5) # 看資料表前5個row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.a. 利用Pandas, 可迅速了解每個資料夾裡面有幾張圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依照class分群後，數各群的數量，並繪圖\n",
    "dfCountPerClass=dfPath.groupby('class').count()\n",
    "dfCountPerClass.rename(columns={'path':'amount of figures'},inplace=True)\n",
    "dfCountPerClass.plot(kind='bar',rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.b. 將圖片路徑資訊分成70% train, 10% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath.head(5) # 看前五筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPath[\"class\"] = dfPath[\"class\"].astype(np.uint8) # 轉換該欄位的資料型態成為uint8\n",
    "\n",
    "dfShuffled=dfPath.sample(frac=1)     # 打亂一下path data\n",
    "\n",
    "dfFrac=dfShuffled.sample(frac=0.05)  # 以下範例，我們只取原資料集的5%來做使用，\n",
    "                                     # 這是為了利於在課堂中快速演練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將已經取了5%的資料拿70%當train, 10%當train_val, 20%當test。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShuffled=dfPath.sample(frac=1)     # 打亂一下path data\n",
    "\n",
    "dfFrac=dfShuffled.sample(frac=0.05)  # 以下範例，我們只取原資料集的5%來做使用，\n",
    "                                     # 這是為了利於在課堂中快速演練。\n",
    "\n",
    "train=dfFrac.sample(frac=0.8) # 將path data隨機取樣，80%的path data當train\n",
    "test=dfFrac.drop(train.index) # 20%的path data當test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.05 # 整體資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.05 * 0.8 # 訓練資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.05 * 0.2 # 測試資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接著，將訓練資料分割出一小部分，留作驗證(validation)用資料\n",
    "\n",
    "trainVal=train.sample(frac=1/8)  # 將train再切1/8做驗證用資料, 存至trainVal\n",
    "train=train.drop(trainVal.index) # 將train的7/8留著，丟去剛切出去的1/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.05 * 0.7 # 最終訓練資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.05 * 0.1 # 最終驗證資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(trainVal.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最終，整體資料拿70%當train, 10%當train_val, 20%當test。\n",
    "print('shape(all figures)=\\t\\t',dfPath.shape)\n",
    "print('shape(fraction of figures)=\\t',dfFrac.shape)\n",
    "print('shape(train)=\\t\\t\\t',train.shape)\n",
    "print('shape(trainVal)=\\t\\t',trainVal.shape)\n",
    "print('shape(test)=\\t\\t\\t',test.shape)\n",
    "\n",
    "#隨便抓三張圖來看\n",
    "for j in range(3):\n",
    "    img=cv2.imread(train['path'].iloc[j])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  2.c. 將圖片載入，存成數值矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoad(dfPath):\n",
    "    paths=dfPath['path'].values\n",
    "    x=np.zeros((len(paths),28,28) )\n",
    "\n",
    "    for j in range(len(paths)):\n",
    "        x[j,:,:]=cv2.imread(paths[j],0)/255\n",
    "    y=dfPath['class'].values\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=dataLoad(train)\n",
    "trainValX,trainValY=dataLoad(trainVal)\n",
    "testX,testY=dataLoad(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:\\t',trainX.shape,trainY.shape)\n",
    "print('trainVal:',trainValX.shape,trainValY.shape)\n",
    "print('test:\\t',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d. 將28X28的圖片特徵轉換成一維"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=trainX.reshape(trainX.shape[0],-1)\n",
    "trainValX=trainValX.reshape(trainValX.shape[0],-1)\n",
    "testX=testX.reshape(testX.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:\\t',trainX.shape,trainY.shape)\n",
    "print('trainVal:',trainValX.shape,trainValY.shape)\n",
    "print('test:\\t',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.e. 以Softmax回歸建立分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression(C=1,multi_class='multinomial',solver='newton-cg')\n",
    "model=lg.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=model.predict(trainValX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將用(trainX,trainY)建立好的模型拿來預測，於(trainValX,trainValY)資料集的準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predY==trainValY).sum()/len(trainValY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上等同於利用model.score()計算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(trainValX,trainValY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.f. 製作分類結果報告，並畫出混淆矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(trainValY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report(trainValY,predY) )\n",
    "\n",
    "mat=confusion_matrix(trainValY,predY)\n",
    "df_cm = pd.DataFrame(mat, index = [i for i in lg.classes_],\n",
    "                  columns = [i for i in lg.classes_])\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.g. 建模: 資料分成train, validation, test三份"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下為建模步驟\n",
    "1. 設定好模型參數後，我們將利用train data來訓練模型。\n",
    "\n",
    "2. 之後，我們將訓練好的模型，拿去檢驗validation data，看模型對於validation data是否有良好的預測結果。\n",
    "\n",
    "3. 若否，則我們將調整模型參數，然後重複上述步驟。\n",
    "\n",
    "4. 最終，我們了解到利用哪些參數可以取得最優模型。得到該最優模型後，我們最後以test data來確立該模型是否足夠完善。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.g.I. 以train data來建立模型，並將該模型以validation data 來檢驗，藉此優化模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，選擇模型參數。\n",
    "\n",
    "例如，調整$C$ (和penalty的強度成反比), 看$C$多大比較適合？\n",
    "\n",
    "另外，順便測試看看$l1$和$l2$之中，哪個penalty比較好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.s. \n",
    "\n",
    "L1= Lasso\n",
    "\n",
    "L2= Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSpace=[0.01,0.1,1,10]\n",
    "penalties=['l1','l2']\n",
    "\n",
    "res=[]\n",
    "for c in cSpace:\n",
    "    for penalty in penalties:\n",
    "        kwargs={'C':c,'penalty':penalty}\n",
    "        print(kwargs)\n",
    "        lg=LogisticRegression(**kwargs)\n",
    "        lg=lg.fit(trainX,trainY)\n",
    "        predY=lg.predict(trainValX)\n",
    "        f1Score=f1_score(predY,trainValY,average='weighted')\n",
    "        res.append((c,penalty,f1Score,lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將以各種不同參數訓練出來的模型和其f1值存至一個資料表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(res,columns=['C','penalty','f1','classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出平均f1最高的參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSorted=df.sort_values('f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=dfSorted[\"classifier\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.coef_.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10 X 784 -> 10 X 28 X 28 -> 28X 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.g.II. 將模型內的權重視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitsWeightVisualizer(c,penalty,f1,classifier,digits):\n",
    "    '''此方法用來視覺化模型內的權重。此方法目前僅適用數字資料集。'''\n",
    "    coefAbs=np.abs(classifier.coef_.reshape(10,28,28)) # 將1維圖像特徵轉回2維\n",
    "    s=sns.cubehelix_palette(light=1, as_cmap=True)     # 建立色票\n",
    "    \n",
    "    fig,axes=plt.subplots(2,2) #建立2X2圖組\n",
    "    fig.set_dpi(100)           #設定該圖組解析度\n",
    "    fig.set_size_inches(4,4)   #設定該圖組大小\n",
    "    fig.suptitle('c= %s, penalty= %s, f1= %.3f'%(c,penalty,f1), y=1.05)\n",
    "    \n",
    "    for idx,j in enumerate(digits):\n",
    "        ax=axes.reshape(-1)[idx]\n",
    "        ax.set_title('digit=%s'%(j))\n",
    "        sns.heatmap(coefAbs[j,:,:],ax=ax,square=True,cmap=s, vmin=0, vmax=1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    digitsWeightVisualizer(*dfSorted.iloc[j,:],[1,2,3,4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由以上我們可看出\n",
    "\n",
    "* l1能導致權重稀疏，將許多權重變成0。\n",
    "* l2強度增加可減小權重大小。\n",
    "\n",
    "以上兩種方式皆可防止overfitting。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.g.III. 以test data來確定建立好的模型是否完善"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們已經利用val data調整參數，得到了一個最好的模型。最後，將該模型用於預測test data，看模型是否也能針對test data有好的結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=best_model.predict(testX)\n",
    "print( classification_report(testY,predY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.h. 另一種更嚴謹的建模方式：k-fold cross validation\n",
    "\n",
    "將train data切五等分(5-fold)，分別以a,b,c,d,e表示。我們將訓練五個模型，每個模型分別取五等分資料中的四份做訓練(train)，剩下一份留做驗證(validation)。每個模型所取得的驗證部分不會重複。\n",
    "\n",
    "|  模型  | 訓練資料 |驗證資料\n",
    "|-------|----------|-----|\n",
    "| 模型1  | a,b,c,d  | e  |\n",
    "| 模型2  | a,b,c,e  | d  |\n",
    "| 模型3  | a,b,d,e  | c  |\n",
    "| 模型4  | a,c,d,e  | b  |\n",
    "| 模型5  | b,c,d,e  | a  |\n",
    "\n",
    "最後，這五個模型每一個都有其對應的驗證資料，我們可利用該資料來檢驗模型好壞，得出五個$f_1$值。將這五個$f_1$算平均($\\bar{f_1}$)以及標準差($\\sigma_{f_1}$)，可推估\n",
    "$\\hat{f_1}=\\bar{f_1}\\pm \\sigma_{f_1}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.h.I. 以5-fold 交叉驗證來調整模型參數: 使用GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "cSpace=[0.01,0.1,1,10]\n",
    "penalties=['l1','l2']\n",
    "kwargs={'C':cSpace,'penalty':penalties}\n",
    "\n",
    "clf = GridSearchCV(cv=5,estimator=LogisticRegression(), param_grid=kwargs,\n",
    "                   n_jobs=-1,scoring='f1_weighted')\n",
    "model=clf.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data=np.random.normal(0,1,(2,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_.predict(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(fake_data) # 這一行和上面那一行是一樣的!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: ```model.predict```做了什麼事情? A: 見API: [按我打開連結](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.h.II. 看哪種參數組合有最高的f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMean=model.cv_results_['mean_test_score'] # 取得mean(f1)\n",
    "scoreStd=model.cv_results_['std_test_score']   # 取得std(f1)\n",
    "\n",
    "params=model.cv_results_['params']\n",
    "\n",
    "#產生x座標軸上各ticks的標籤\n",
    "xTickLabels=['('+str(param['penalty'])+','+str(param['C']) +')' for param in params]\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,4),dpi=100)\n",
    "\n",
    "#將各f1畫成長條圖\n",
    "ax.bar(np.arange(8), scoreMean, yerr=scoreStd)\n",
    "ax.set_xticks(np.arange(8))\n",
    "ax.set_xticklabels(xTickLabels)\n",
    "ax.set_ylabel('f1 score')\n",
    "ax.set_xlabel('parameter set, i.e. (penalty, C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型最佳參數為何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.h.III. 最後，拿最好的模型，去看該模型是否亦適用於test data。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=model.best_estimator_.predict(testX)\n",
    "print( classification_report(testY,predY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#索引)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
